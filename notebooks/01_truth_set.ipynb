{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51ee9ae-426e-43d9-a0d6-8be8bf1f7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import grpc\n",
    "from senzing_grpc import SzAbstractFactoryGrpc\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4c96a-8e82-40de-accf-01acf994c08b",
   "metadata": {},
   "source": [
    "## Download the Senzing Truth Set\n",
    "\n",
    "Pulls three JSONL files (customers, reference, watchlist) from the official Senzing GitHub repository and saves them to `/workspace/data`.  These files are Senzing's public demo dataset and are designed specifically for exploring entity resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55cc99f8-9cbd-4014-9505-437f28f575a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading truth set files...\n",
      "✅ Downloaded customers.jsonl\n",
      "✅ Downloaded reference.jsonl\n",
      "✅ Downloaded watchlist.jsonl\n",
      "\n",
      "Truth sets downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "truth_set_urls = {\n",
    "    'customers': 'https://raw.githubusercontent.com/Senzing/truth-sets/main/truthsets/demo/customers.jsonl',\n",
    "    'reference': 'https://raw.githubusercontent.com/Senzing/truth-sets/main/truthsets/demo/reference.jsonl',\n",
    "    'watchlist': 'https://raw.githubusercontent.com/Senzing/truth-sets/main/truthsets/demo/watchlist.jsonl'\n",
    "}\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('/workspace/data', exist_ok=True)\n",
    "\n",
    "print(\"Downloading truth set files...\")\n",
    "for name, url in truth_set_urls.items():\n",
    "    filepath = f'/workspace/data/{name}.jsonl'\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "    print(f\"✅ Downloaded {name}.jsonl\")\n",
    "\n",
    "print(\"\\nTruth sets downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf492af-e0fa-4b20-9e8c-f0e9a5a50563",
   "metadata": {},
   "source": [
    "## Preview the Raw Data\n",
    "\n",
    "Prints the first three customer records so you can see what the raw input looks like before any entity resolution happens.  Also counts the total number of records in each file so you know what Senzing is working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59313f64-5ad1-46e2-89fc-505e63ca589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample customer records:\n",
      "============================================================\n",
      "\n",
      "Record 1:\n",
      "{\n",
      "  \"DATA_SOURCE\": \"CUSTOMERS\",\n",
      "  \"RECORD_ID\": \"1001\",\n",
      "  \"RECORD_TYPE\": \"PERSON\",\n",
      "  \"PRIMARY_NAME_LAST\": \"Smith\",\n",
      "  \"PRIMARY_NAME_FIRST\": \"Robert\",\n",
      "  \"DATE_OF_BIRTH\": \"12/11/1978\",\n",
      "  \"ADDR_TYPE\": \"MAILING\",\n",
      "  \"ADDR_LINE1\": \"123 Main Street, Las Vegas NV 89132\",\n",
      "  \"PHONE_TYPE\": \"HOME\",\n",
      "  \"PHONE_NUMBER\": \"702-919-1300\",\n",
      "  \"DATE\": \"1/2/18\",\n",
      "  \"STATUS\": \"Active\",\n",
      "  \"AMOUNT\": \"100\"\n",
      "}\n",
      "\n",
      "Record 2:\n",
      "{\n",
      "  \"DATA_SOURCE\": \"CUSTOMERS\",\n",
      "  \"RECORD_ID\": \"1002\",\n",
      "  \"RECORD_TYPE\": \"PERSON\",\n",
      "  \"PRIMARY_NAME_LAST\": \"Smith\",\n",
      "  \"PRIMARY_NAME_FIRST\": \"Bob\",\n",
      "  \"DATE_OF_BIRTH\": \"11/12/1978\",\n",
      "  \"ADDR_TYPE\": \"HOME\",\n",
      "  \"ADDR_LINE1\": \"1515 Adela Lane\",\n",
      "  \"ADDR_CITY\": \"Las Vegas\",\n",
      "  \"ADDR_STATE\": \"NV\",\n",
      "  \"ADDR_POSTAL_CODE\": \"89111\",\n",
      "  \"PHONE_TYPE\": \"MOBILE\",\n",
      "  \"PHONE_NUMBER\": \"702-919-1300\",\n",
      "  \"DATE\": \"3/10/17\",\n",
      "  \"STATUS\": \"Inactive\",\n",
      "  \"AMOUNT\": \"200\"\n",
      "}\n",
      "\n",
      "Record 3:\n",
      "{\n",
      "  \"DATA_SOURCE\": \"CUSTOMERS\",\n",
      "  \"RECORD_ID\": \"1003\",\n",
      "  \"RECORD_TYPE\": \"PERSON\",\n",
      "  \"PRIMARY_NAME_LAST\": \"Smith\",\n",
      "  \"PRIMARY_NAME_FIRST\": \"Bob\",\n",
      "  \"PRIMARY_NAME_MIDDLE\": \"J\",\n",
      "  \"DATE_OF_BIRTH\": \"12/11/1978\",\n",
      "  \"EMAIL_ADDRESS\": \"bsmith@work.com\",\n",
      "  \"DATE\": \"4/9/16\",\n",
      "  \"STATUS\": \"Inactive\",\n",
      "  \"AMOUNT\": \"300\"\n",
      "}\n",
      "\n",
      "============================================================\n",
      "Record counts:\n",
      "  customers: 120 records\n",
      "  reference: 22 records\n",
      "  watchlist: 17 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample customer records:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with open('/workspace/data/customers.jsonl', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 3:  # Show first 3 records\n",
    "            record = json.loads(line)\n",
    "            print(f\"\\nRecord {i+1}:\")\n",
    "            print(json.dumps(record, indent=2))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# Count total records\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Record counts:\")\n",
    "for name in ['customers', 'reference', 'watchlist']:\n",
    "    with open(f'/workspace/data/{name}.jsonl', 'r') as f:\n",
    "        count = sum(1 for _ in f)\n",
    "    print(f\"  {name}: {count} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd8b88-26ef-4e18-8bcb-97b5802a659a",
   "metadata": {},
   "source": [
    "## Connect to Senzing\n",
    "\n",
    "Opens a gRPC channel to the Senzing service and creates the engine instance that all subsequent API calls will use.  The connection details come from environment variables set in the Docker Compose file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5811f630-4e51-4add-8b1a-53d52dca25d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Senzing at senzing:8261...\n",
      "✅ Connected to Senzing successfully!\n"
     ]
    }
   ],
   "source": [
    "grpc_host = os.getenv('SENZING_GRPC_HOST', 'senzing')\n",
    "grpc_port = os.getenv('SENZING_GRPC_PORT', '8261')\n",
    "\n",
    "# Create gRPC channel and connect to Senzing\n",
    "grpc_url = f\"{grpc_host}:{grpc_port}\"\n",
    "print(f\"Connecting to Senzing at {grpc_url}...\")\n",
    "\n",
    "try:\n",
    "    # Create an insecure gRPC channel\n",
    "    grpc_channel = grpc.insecure_channel(grpc_url)\n",
    "    \n",
    "    # Create the factory using the channel\n",
    "    sz_factory = SzAbstractFactoryGrpc(grpc_channel=grpc_channel)\n",
    "    \n",
    "    # Create the engine instance\n",
    "    sz_engine = sz_factory.create_engine()\n",
    "    \n",
    "    print(\"✅ Connected to Senzing successfully!\")\n",
    "    \n",
    "except Exception as err:\n",
    "    print(f\"❌ Error connecting to Senzing: {err}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a9b4b-c4b0-4e87-a61f-481e09c97cc1",
   "metadata": {},
   "source": [
    "## Load Truth Set Data into Senzing\n",
    "\n",
    "Iterates through all three JSONL files and loads each record into Senzing via `add_record()`.  As records are ingested, Senzing is running entity resolution in the background, which is why some customer records will later appear merged into a single entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a1643ee-176f-4bb9-8a92-aabfc261accf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading truth set data into Senzing...\n",
      "============================================================\n",
      "\n",
      "Loading CUSTOMERS...\n",
      "  Loaded 100 records...\n",
      "  ✅ Loaded 120 records from CUSTOMERS\n",
      "\n",
      "Loading REFERENCE...\n",
      "  ✅ Loaded 22 records from REFERENCE\n",
      "\n",
      "Loading WATCHLIST...\n",
      "  ✅ Loaded 17 records from WATCHLIST\n",
      "\n",
      "============================================================\n",
      "✅ All truth set data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "data_sources = {\n",
    "    'CUSTOMERS': '/workspace/data/customers.jsonl',\n",
    "    'REFERENCE': '/workspace/data/reference.jsonl',\n",
    "    'WATCHLIST': '/workspace/data/watchlist.jsonl'\n",
    "}\n",
    "\n",
    "print(\"Loading truth set data into Senzing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for data_source, filepath in data_sources.items():\n",
    "    print(f\"\\nLoading {data_source}...\")\n",
    "    \n",
    "    records_loaded = 0\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            record_id = record['RECORD_ID']\n",
    "            \n",
    "            try:\n",
    "                sz_engine.add_record(data_source, record_id, line.strip())\n",
    "                records_loaded += 1\n",
    "                \n",
    "                # Print progress every 100 records\n",
    "                if records_loaded % 100 == 0:\n",
    "                    print(f\"  Loaded {records_loaded} records...\")\n",
    "                    \n",
    "            except Exception as err:\n",
    "                print(f\"  ❌ Error loading record {record_id}: {err}\")\n",
    "    \n",
    "    print(f\"  ✅ Loaded {records_loaded} records from {data_source}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ All truth set data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7114802-8e67-4662-87d5-925c87781064",
   "metadata": {},
   "source": [
    "## Look Up a Resolved Entity by Record ID\n",
    "\n",
    "Fetches the entity that Senzing resolved for customer record 1001 and shows which other records were merged into it.  This is the core payoff of entity resolution: multiple source records collapsed into one unified entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99e3f7a-9f39-46e8-a800-ccc12f78cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up customer record 1001...\n",
      "============================================================\n",
      "\n",
      "Entity ID: 2\n",
      "Number of records in this entity: 4\n",
      "\n",
      "Records that were merged into this entity:\n",
      "  - CUSTOMERS: 1002\n",
      "  - CUSTOMERS: 1001\n",
      "  - CUSTOMERS: 1003\n",
      "  - CUSTOMERS: 1004\n"
     ]
    }
   ],
   "source": [
    "print(\"Looking up customer record 1001...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = sz_engine.get_entity_by_record_id('CUSTOMERS', '1001')\n",
    "    entity = json.loads(result)\n",
    "    \n",
    "    resolved = entity['RESOLVED_ENTITY']\n",
    "    \n",
    "    print(f\"\\nEntity ID: {resolved['ENTITY_ID']}\")\n",
    "    print(f\"Number of records in this entity: {len(resolved['RECORDS'])}\")\n",
    "    \n",
    "    print(\"\\nRecords that were merged into this entity:\")\n",
    "    for record in resolved['RECORDS']:\n",
    "        print(f\"  - {record['DATA_SOURCE']}: {record['RECORD_ID']}\")\n",
    "    \n",
    "    # Show some features of the resolved entity\n",
    "    if 'NAME_DATA' in resolved:\n",
    "        print(f\"\\nNames found:\")\n",
    "        for name in resolved['NAME_DATA'][:3]:  # Show first 3\n",
    "            print(f\"  - {name}\")\n",
    "    \n",
    "    if 'ADDRESS_DATA' in resolved:\n",
    "        print(f\"\\nAddresses found:\")\n",
    "        for addr in resolved['ADDRESS_DATA'][:3]:  # Show first 3\n",
    "            print(f\"  - {addr}\")\n",
    "    \n",
    "except Exception as err:\n",
    "    print(f\"❌ Error: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe4900-94ce-4171-9d32-3c43894f391d",
   "metadata": {},
   "source": [
    "## Search by Attributes\n",
    "\n",
    "Searches Senzing for entities matching the name \"Robert Smith\" and prints the match details for each result, including the match level, match key, ER rule used, and name similarity score.  This shows how Senzing ranks and explains its fuzzy matching decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fe094c-0ddd-482d-a67f-037927b59ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for entities named 'Robert Smith'...\n",
      "============================================================\n",
      "\n",
      "Found 3 matching entities:\n",
      "\n",
      "============================================================\n",
      "Match 1:\n",
      "============================================================\n",
      "\n",
      "Match Details:\n",
      "  Match Level: POSSIBLY_SAME\n",
      "  Match Key: +NAME\n",
      "  ER Rule: SNAME\n",
      "\n",
      "  Name Match Score:\n",
      "    Search: Robert Smith\n",
      "    Found: Robert Smith\n",
      "    Score: 100/100\n",
      "    Score Bucket: SAME\n",
      "\n",
      "Entity Information:\n",
      "  Entity ID: 2\n",
      "  Entity Name: Robert Smith\n",
      "\n",
      "============================================================\n",
      "Match 2:\n",
      "============================================================\n",
      "\n",
      "Match Details:\n",
      "  Match Level: POSSIBLY_SAME\n",
      "  Match Key: +NAME\n",
      "  ER Rule: SNAME\n",
      "\n",
      "  Name Match Score:\n",
      "    Search: Robert Smith\n",
      "    Found: Robbie Smith\n",
      "    Score: 97/100\n",
      "    Score Bucket: CLOSE\n",
      "\n",
      "Entity Information:\n",
      "  Entity ID: 6\n",
      "  Entity Name: Robert E Smith Sr\n",
      "\n",
      "============================================================\n",
      "Match 3:\n",
      "============================================================\n",
      "\n",
      "Match Details:\n",
      "  Match Level: POSSIBLY_SAME\n",
      "  Match Key: +NAME\n",
      "  ER Rule: SNAME\n",
      "\n",
      "  Name Match Score:\n",
      "    Search: Robert Smith\n",
      "    Found: Robert Smith\n",
      "    Score: 100/100\n",
      "    Score Bucket: SAME\n",
      "\n",
      "Entity Information:\n",
      "  Entity ID: 146\n",
      "  Entity Name: Robert Smith\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching for entities named 'Robert Smith'...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "search_attributes = {\n",
    "    \"NAME_FIRST\": \"Robert\",\n",
    "    \"NAME_LAST\": \"Smith\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    search_json = json.dumps(search_attributes)\n",
    "    result = sz_engine.search_by_attributes(search_json)\n",
    "    search_results = json.loads(result)\n",
    "    \n",
    "    if 'RESOLVED_ENTITIES' in search_results:\n",
    "        print(f\"\\nFound {len(search_results['RESOLVED_ENTITIES'])} matching entities:\")\n",
    "        \n",
    "        for i, entity_result in enumerate(search_results['RESOLVED_ENTITIES']):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Match {i+1}:\")\n",
    "            print('='*60)\n",
    "            \n",
    "            # Match information - shows WHY this matched\n",
    "            if 'MATCH_INFO' in entity_result:\n",
    "                match_info = entity_result['MATCH_INFO']\n",
    "                print(f\"\\nMatch Details:\")\n",
    "                print(f\"  Match Level: {match_info.get('MATCH_LEVEL_CODE', 'N/A')}\")\n",
    "                print(f\"  Match Key: {match_info.get('MATCH_KEY', 'N/A')}\")\n",
    "                print(f\"  ER Rule: {match_info.get('ERRULE_CODE', 'N/A')}\")\n",
    "                \n",
    "                # Show feature scores if available\n",
    "                if 'FEATURE_SCORES' in match_info and 'NAME' in match_info['FEATURE_SCORES']:\n",
    "                    name_scores = match_info['FEATURE_SCORES']['NAME']\n",
    "                    if name_scores:\n",
    "                        print(f\"\\n  Name Match Score:\")\n",
    "                        for score in name_scores[:1]:  # Show first name match\n",
    "                            print(f\"    Search: {score.get('INBOUND_FEAT_DESC', 'N/A')}\")\n",
    "                            print(f\"    Found: {score.get('CANDIDATE_FEAT_DESC', 'N/A')}\")\n",
    "                            print(f\"    Score: {score.get('SCORE', 'N/A')}/100\")\n",
    "                            print(f\"    Score Bucket: {score.get('SCORE_BUCKET', 'N/A')}\")\n",
    "            \n",
    "            # Get entity details\n",
    "            if 'ENTITY' in entity_result and 'RESOLVED_ENTITY' in entity_result['ENTITY']:\n",
    "                resolved = entity_result['ENTITY']['RESOLVED_ENTITY']\n",
    "                \n",
    "                print(f\"\\nEntity Information:\")\n",
    "                print(f\"  Entity ID: {resolved.get('ENTITY_ID', 'N/A')}\")\n",
    "                \n",
    "                # Show entity name if available\n",
    "                if 'ENTITY_NAME' in resolved:\n",
    "                    print(f\"  Entity Name: {resolved['ENTITY_NAME']}\")\n",
    "                \n",
    "                # Show which data sources contributed\n",
    "                if 'RECORDS' in resolved:\n",
    "                    records = resolved['RECORDS']\n",
    "                    sources = set(r['DATA_SOURCE'] for r in records)\n",
    "                    print(f\"  Data Sources: {', '.join(sources)}\")\n",
    "                    print(f\"  Total Records: {len(records)}\")\n",
    "                    \n",
    "                    print(f\"\\n  Record Details:\")\n",
    "                    for rec in records:\n",
    "                        print(f\"    - {rec['DATA_SOURCE']}: {rec['RECORD_ID']}\")\n",
    "                \n",
    "                # Show additional entity attributes\n",
    "                if 'NAME_DATA' in resolved:\n",
    "                    print(f\"\\n  Names ({len(resolved['NAME_DATA'])} found):\")\n",
    "                    for name in resolved['NAME_DATA'][:3]:\n",
    "                        print(f\"    - {name}\")\n",
    "                \n",
    "                if 'ADDRESS_DATA' in resolved:\n",
    "                    print(f\"\\n  Addresses ({len(resolved['ADDRESS_DATA'])} found):\")\n",
    "                    for addr in resolved['ADDRESS_DATA'][:3]:\n",
    "                        print(f\"    - {addr}\")\n",
    "                \n",
    "                if 'PHONE_DATA' in resolved:\n",
    "                    print(f\"\\n  Phone Numbers ({len(resolved['PHONE_DATA'])} found):\")\n",
    "                    for phone in resolved['PHONE_DATA'][:3]:\n",
    "                        print(f\"    - {phone}\")\n",
    "                \n",
    "                if 'EMAIL_DATA' in resolved:\n",
    "                    print(f\"\\n  Emails ({len(resolved['EMAIL_DATA'])} found):\")\n",
    "                    for email in resolved['EMAIL_DATA'][:3]:\n",
    "                        print(f\"    - {email}\")\n",
    "    else:\n",
    "        print(\"No matching entities found\")\n",
    "        \n",
    "except Exception as err:\n",
    "    import traceback\n",
    "    print(f\"❌ Error: {err}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3e616-1046-49bc-91f7-41431afdd72c",
   "metadata": {},
   "source": [
    "## Find Entities Matched Across Multiple Data Sources\n",
    "\n",
    "Samples a handful of customer record IDs and checks whether each one resolved into an entity that also contains records from the REFERENCE or WATCHLIST sources.  Cross-source matches are some of the most valuable outputs of entity resolution since they flag customers who appear on reference lists or watchlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e92caa5-90eb-485d-a191-74e15e9b296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding entities with records from multiple data sources...\n",
      "============================================================\n",
      "\n",
      "Found 3 multi-source entities:\n",
      "\n",
      "  Entity 6: Robert E Smith Sr\n",
      "    Sources: WATCHLIST, CUSTOMERS\n",
      "    Total records: 2\n",
      "    Record breakdown:\n",
      "      - CUSTOMERS: 1005\n",
      "      - WATCHLIST: 1006\n",
      "\n",
      "  Entity 7: Eddie Kusha\n",
      "    Sources: WATCHLIST, CUSTOMERS\n",
      "    Total records: 5\n",
      "    Record breakdown:\n",
      "      - CUSTOMERS: 1009\n",
      "      - CUSTOMERS: 1010\n",
      "      - CUSTOMERS: 1011\n",
      "      - WATCHLIST: 1012\n",
      "      - WATCHLIST: 1014\n",
      "\n",
      "  Entity 15: Marsha Kusha\n",
      "    Sources: WATCHLIST, CUSTOMERS\n",
      "    Total records: 2\n",
      "    Record breakdown:\n",
      "      - CUSTOMERS: 1020\n",
      "      - WATCHLIST: 1021\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding entities with records from multiple data sources...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# We'll sample some customer records and see if they matched with reference or watchlist\n",
    "sample_customer_ids = ['1001', '1002', '1003', '1004', '1005', '1010', '1020', '1030']\n",
    "\n",
    "multi_source_entities = []\n",
    "\n",
    "for customer_id in sample_customer_ids:\n",
    "    try:\n",
    "        result = sz_engine.get_entity_by_record_id('CUSTOMERS', customer_id)\n",
    "        entity = json.loads(result)\n",
    "        \n",
    "        if 'RESOLVED_ENTITY' in entity:\n",
    "            records = entity['RESOLVED_ENTITY']['RECORDS']\n",
    "            sources = set(r['DATA_SOURCE'] for r in records)\n",
    "            \n",
    "            if len(sources) > 1:\n",
    "                entity_name = entity['RESOLVED_ENTITY'].get('ENTITY_NAME', 'Unknown')\n",
    "                multi_source_entities.append({\n",
    "                    'entity_id': entity['RESOLVED_ENTITY']['ENTITY_ID'],\n",
    "                    'entity_name': entity_name,\n",
    "                    'sources': sources,\n",
    "                    'record_count': len(records),\n",
    "                    'records': records\n",
    "                })\n",
    "    except:\n",
    "        pass  # Record might not exist\n",
    "\n",
    "if multi_source_entities:\n",
    "    print(f\"\\nFound {len(multi_source_entities)} multi-source entities:\")\n",
    "    for e in multi_source_entities:\n",
    "        print(f\"\\n  Entity {e['entity_id']}: {e['entity_name']}\")\n",
    "        print(f\"    Sources: {', '.join(e['sources'])}\")\n",
    "        print(f\"    Total records: {e['record_count']}\")\n",
    "        print(f\"    Record breakdown:\")\n",
    "        for rec in e['records']:\n",
    "            print(f\"      - {rec['DATA_SOURCE']}: {rec['RECORD_ID']}\")\n",
    "else:\n",
    "    print(\"\\nNo multi-source matches found in this sample\")\n",
    "    print(\"(This is normal - not all customer records will have reference/watchlist matches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b2e34-0c28-467b-a983-6ec6a98b2b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
