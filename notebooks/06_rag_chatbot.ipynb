{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9521e2ad-855e-4993-87af-d1e4d842cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import lancedb\n",
    "import dspy\n",
    "\n",
    "import grpc\n",
    "import json\n",
    "from senzing import SzEngine\n",
    "from senzing_grpc import SzAbstractFactoryGrpc\n",
    "from senzing import SzEngineFlags\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4de5b-8226-4981-9b24-2d2406fefb90",
   "metadata": {},
   "source": [
    "## Load the Embedding Model\n",
    "\n",
    "Loads the same `all-MiniLM-L6-v2` model that was used to create the vectors in the previous notebook.  It is critical that the query embedding and the stored embeddings come from the same model, otherwise the similarity scores will be meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2e9c54-19b5-4ea0-9dda-9b94faad2a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291d583794f846c38d2b7248bda90be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the same embedding model used to create vectors\n",
    "print(\"Loading embedding model...\")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Embedding model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86e5a4-9f66-424c-9371-32f68dce53da",
   "metadata": {},
   "source": [
    "## Connect to LanceDB\n",
    "\n",
    "Opens the existing LanceDB database and the `entities` table created in the previous notebook.  The row count printed here should match the 196 entities we stored during vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c25b56a9-9dcd-4140-9368-b4b0f7be3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LanceDB\n",
      "Total entities available: 196\n"
     ]
    }
   ],
   "source": [
    "db = lancedb.connect('/workspace/lancedb_data')\n",
    "table = db.open_table('entities')\n",
    "\n",
    "print(f\"Connected to LanceDB\")\n",
    "print(f\"Total entities available: {table.count_rows()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7289bf-2e00-409f-93ac-f24b46c0202d",
   "metadata": {},
   "source": [
    "## Rebuild the Knowledge Graph from Senzing\n",
    "\n",
    "Reconnects briefly to Senzing to re-export entities and rebuild the NetworkX graph with nodes and relationship edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7661b5b1-ed93-44f7-a269-37c05e9b2ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge graph rebuilt:\n",
      "  Nodes: 196\n",
      "  Edges: 233\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# Get all entities\n",
    "all_entities = table.to_pandas()\n",
    "\n",
    "SENZING_HOST = os.getenv('SENZING_GRPC_HOST', 'senzing')\n",
    "SENZING_PORT = os.getenv('SENZING_GRPC_PORT', '8261')\n",
    "\n",
    "grpc_url = f\"{SENZING_HOST}:{SENZING_PORT}\"\n",
    "grpc_channel = grpc.insecure_channel(grpc_url)\n",
    "sz_abstract_factory = SzAbstractFactoryGrpc(grpc_channel)\n",
    "sz_engine = sz_abstract_factory.create_engine()\n",
    "\n",
    "# Quick export to rebuild graph\n",
    "entities = []\n",
    "export_handle = sz_engine.export_json_entity_report(\n",
    "    flags=SzEngineFlags.SZ_EXPORT_INCLUDE_ALL_ENTITIES | \n",
    "          SzEngineFlags.SZ_ENTITY_INCLUDE_RECORD_JSON_DATA\n",
    ")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        entity_json = sz_engine.fetch_next(export_handle)\n",
    "        if not entity_json:\n",
    "            break\n",
    "        entities.append(json.loads(entity_json))\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "sz_engine.close_export_report(export_handle)\n",
    "\n",
    "# Build graph nodes\n",
    "for entity in entities:\n",
    "    entity_data = entity.get('RESOLVED_ENTITY', {})\n",
    "    entity_id = entity_data.get('ENTITY_ID')\n",
    "    records = entity_data.get('RECORDS', [])\n",
    "    \n",
    "    if not records:\n",
    "        continue\n",
    "    \n",
    "    first_record = records[0]\n",
    "    json_data = first_record.get('JSON_DATA', {})\n",
    "    record_type = json_data.get('RECORD_TYPE', 'UNKNOWN')\n",
    "    \n",
    "    name = json_data.get('PRIMARY_NAME_FULL')\n",
    "    if not name:\n",
    "        name_list = json_data.get('NAMES', [])\n",
    "        for name_obj in name_list:\n",
    "            name = name_obj.get('NAME_FULL') or name_obj.get('PRIMARY_NAME_ORG') or name_obj.get('NAME_ORG')\n",
    "            if name:\n",
    "                break\n",
    "    \n",
    "    if not name:\n",
    "        name = f\"Entity {entity_id}\"\n",
    "    \n",
    "    data_sources = list(set([r.get('DATA_SOURCE') for r in records]))\n",
    "    \n",
    "    G.add_node(\n",
    "        entity_id,\n",
    "        name=name,\n",
    "        type=record_type,\n",
    "        num_records=len(records),\n",
    "        data_sources=data_sources\n",
    "    )\n",
    "\n",
    "# Build graph edges\n",
    "for entity in entities:\n",
    "    entity_data = entity.get('RESOLVED_ENTITY', {})\n",
    "    anchor_entity_id = entity_data.get('ENTITY_ID')\n",
    "    \n",
    "    for record in entity_data.get('RECORDS', []):\n",
    "        relationships = record.get('JSON_DATA', {}).get('RELATIONSHIPS', [])\n",
    "        \n",
    "        for rel in relationships:\n",
    "            pointer_key = rel.get('REL_POINTER_KEY')\n",
    "            pointer_role = rel.get('REL_POINTER_ROLE', 'related')\n",
    "            \n",
    "            for target_entity in entities:\n",
    "                target_data = target_entity.get('RESOLVED_ENTITY', {})\n",
    "                target_entity_id = target_data.get('ENTITY_ID')\n",
    "                \n",
    "                for target_record in target_data.get('RECORDS', []):\n",
    "                    if target_record.get('RECORD_ID') == pointer_key:\n",
    "                        if anchor_entity_id != target_entity_id:\n",
    "                            G.add_edge(\n",
    "                                anchor_entity_id,\n",
    "                                target_entity_id,\n",
    "                                relationship=pointer_role\n",
    "                            )\n",
    "                        break\n",
    "\n",
    "# Close Senzing\n",
    "\n",
    "grpc_channel.close()\n",
    "\n",
    "print(f\"Knowledge graph rebuilt:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88af5d0-adfe-4441-bfcd-44e2668752ce",
   "metadata": {},
   "source": [
    "## Configure DSPy with Claude\n",
    "\n",
    "Sets up DSPy to use Claude Sonnet as the language model backend.  The API key is read from an environment variable, stored in `.env` in the root directory of the repo, so it never needs to be hardcoded in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c19b0d5-d8b7-4990-ade6-9136671e75fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy configured with Claude 4.5 Sonnet\n"
     ]
    }
   ],
   "source": [
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"ANTHROPIC_API_KEY not found in environment\")\n",
    "\n",
    "lm = dspy.LM(\n",
    "    model='anthropic/claude-sonnet-4-5-20250929',\n",
    "    api_key=ANTHROPIC_API_KEY,\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm=lm)\n",
    "\n",
    "print(\"DSPy configured with Claude 4.5 Sonnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e58dc-97fb-4767-9dcd-fb81884382cf",
   "metadata": {},
   "source": [
    "## Define the DSPy Signature and Module\n",
    "\n",
    "Defines the contract for the RAG pipeline using a DSPy `Signature`: the LLM receives a `context` field (the graph data we assembled) and a `question` field, and must produce an `answer`.  The `GraphRAG` module wraps this in a `ChainOfThought` call, which prompts the model to reason step by step before answering rather than jumping straight to a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d1aa1c-9c0e-4e7e-bb3e-095dddf3e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DSPy signature for Graph RAG\n",
    "class GraphRAGSignature(dspy.Signature):\n",
    "    \"\"\"Answer questions about a corporate ownership and sanctions knowledge graph.\"\"\"\n",
    "    \n",
    "    context = dspy.InputField(desc=\"Knowledge graph context including entities and relationships\")\n",
    "    question = dspy.InputField(desc=\"User's question about the knowledge graph\")\n",
    "    answer = dspy.OutputField(desc=\"Detailed answer based on the knowledge graph context\")\n",
    "\n",
    "# Create DSPy module\n",
    "class GraphRAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(GraphRAGSignature)\n",
    "    \n",
    "    def forward(self, context, question):\n",
    "        return self.generate_answer(context=context, question=question)\n",
    "\n",
    "# Initialize\n",
    "graph_rag = GraphRAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdc2ac-4e25-4108-9565-33c6195aee31",
   "metadata": {},
   "source": [
    "## Define function to ask the knowledge graph\n",
    "\n",
    "This is the core of the pipeline.  Given a user question it runs four steps: embed the question and search LanceDB for the top 10 most similar entities, expand that set by pulling 1-hop neighbors from the NetworkX graph, format the combined entity set into a structured text context, then pass that context and the question to the DSPy module.  The graph expansion step is what makes this a knowledge graph RAG rather than a plain vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d51d850-e8cb-496c-84c0-90f3edee1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_knowledge_graph(question, top_k=10):\n",
    "    \"\"\"\n",
    "    Simple RAG: Search -> Expand -> Format -> Ask LLM\n",
    "    \"\"\"\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Step 1: Vector search\n",
    "    question_embedding = embedding_model.encode(question).tolist()\n",
    "    results = table.search(question_embedding).limit(top_k).to_list()\n",
    "    \n",
    "    print(f\"Found {len(results)} relevant entities\")\n",
    "    \n",
    "    # Step 2: Collect entity IDs and expand to neighbors\n",
    "    entity_ids = set()\n",
    "    for r in results:\n",
    "        entity_ids.add(r['entity_id'])\n",
    "        \n",
    "        # Add neighbors from graph\n",
    "        if r['entity_id'] in G:\n",
    "            neighbors = list(G.neighbors(r['entity_id']))[:5]\n",
    "            entity_ids.update(neighbors)\n",
    "    \n",
    "    print(f\"Expanded to {len(entity_ids)} entities (including neighbors)\")\n",
    "    \n",
    "    # Step 3: Build simple context\n",
    "    context_parts = [\"ENTITIES:\\n\"]\n",
    "    \n",
    "    for entity_id in list(entity_ids)[:30]:  # Cap at 30 entities\n",
    "        # Get entity info\n",
    "        entity_info = table.search().where(f\"entity_id = {entity_id}\").limit(1).to_list()\n",
    "        if not entity_info:\n",
    "            continue\n",
    "        \n",
    "        info = entity_info[0]\n",
    "        context_parts.append(f\"- {info['name']} ({info['type']})\")\n",
    "        context_parts.append(f\"  Sources: {info['data_sources']}, Records: {info['num_records']}\")\n",
    "        \n",
    "        if info.get('risks'):\n",
    "            context_parts.append(f\"  Risks: {info['risks']}\")\n",
    "        \n",
    "        # Add relationships\n",
    "        if entity_id in G:\n",
    "            rels = []\n",
    "            for neighbor_id in list(G.neighbors(entity_id))[:3]:\n",
    "                edge_data = G.get_edge_data(entity_id, neighbor_id)\n",
    "                neighbor = G.nodes[neighbor_id]\n",
    "                rel_type = edge_data.get('relationship', 'connected to') if edge_data else 'connected to'\n",
    "                rels.append(f\"{rel_type} {neighbor['name']}\")\n",
    "            \n",
    "            if rels:\n",
    "                context_parts.append(f\"  Relationships: {'; '.join(rels)}\")\n",
    "        \n",
    "        context_parts.append(\"\")\n",
    "    \n",
    "    context = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Step 4: Ask LLM\n",
    "    print(\"Querying LLM...\")\n",
    "    result = graph_rag(context=context, question=question)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANSWER\")\n",
    "    print(\"=\"*70)\n",
    "    print(result.answer)\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556393d4-5f59-450e-9592-6ec4a2544f05",
   "metadata": {},
   "source": [
    "## Interactive Chatbot Session\n",
    "\n",
    "Runs a simple read-eval-print loop so participants can ask free-form questions about the dataset.  Type `quit` or `exit` to stop.  The example questions in the notebook output are a good starting point: try asking about specific named individuals, risk categories, ownership chains, or patterns that might indicate fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013411e-a577-4aee-b8b5-f306031a3ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Graph RAG - Interactive Session\n",
      "======================================================================\n",
      "Ask any question about the corporate ownership and sanctions data.\n",
      "The system will search LanceDB and query the knowledge graph.\n",
      "Type 'quit' to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  who specifically is listed as an oligarch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: who specifically is listed as an oligarch\n",
      "======================================================================\n",
      "Found 10 relevant entities\n",
      "Expanded to 19 entities (including neighbors)\n",
      "Querying LLM...\n",
      "\n",
      "======================================================================\n",
      "ANSWER\n",
      "======================================================================\n",
      "**Suleyman Abusaidovich KERIMOV** is the only person specifically listed as an oligarch in this knowledge graph.\n",
      "\n",
      "According to the data, Suleyman Abusaidovich KERIMOV has the following risk classifications:\n",
      "- **role.oligarch** - Designated as an oligarch\n",
      "- poi - Person of interest\n",
      "- sanction - Under sanctions\n",
      "- role.pep - Politically exposed person\n",
      "\n",
      "He has family relationships with:\n",
      "- Firuza Nazimovna Kerimova (family member)\n",
      "- Amina Suleymanovna Kerimova (family member)\n",
      "- Gulnara Suleimanova KERIMOVA (family member)\n",
      "\n",
      "Additionally, his family member Said Kerimov appears to control several Russian organizations (ООО \"ЗАРЕЧЬЕ-ЭСТЕЙТ\", ООО \"НАЦИОНАЛЬНАЯ КИНОСЕТЬ\", ООО \"ВЕНЧЕР МЕНЕДЖМЕНТ ЛИМИТЕД\"), and multiple family members carry sanctions and related party risk flags.\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  who are the oligarchs in this data and what organizations are they associated with?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: who are the oligarchs in this data and what organizations are they associated with?\n",
      "======================================================================\n",
      "Found 10 relevant entities\n",
      "Expanded to 18 entities (including neighbors)\n",
      "Querying LLM...\n",
      "\n",
      "======================================================================\n",
      "ANSWER\n",
      "======================================================================\n",
      "Based on the knowledge graph data, there is **one oligarch** identified:\n",
      "\n",
      "**Suleyman Abusaidovich KERIMOV**\n",
      "- Risk Profile: Oligarch, Person of Interest (POI), Sanctioned, Politically Exposed Person (PEP)\n",
      "- Source: OPEN-SANCTIONS\n",
      "\n",
      "**Organizations Associated with Kerimov (through family network):**\n",
      "\n",
      "The oligarch is connected to several Russian organizations through his son, Said Kerimov, who controls or founded the following entities:\n",
      "\n",
      "1. **ООО \"ГРАНДЕКО\"** - Sanctioned/linked entity, POI\n",
      "2. **ООО \"НАЦИОНАЛЬНАЯ КИНОСЕТЬ\"** (National Cinema Network) - Sanctioned/linked entity\n",
      "3. **ООО \"ЗАРЕЧЬЕ-ЭСТЕЙТ\"** - Sanctioned/linked entity\n",
      "4. **ООО \"ВЕНЧЕР МЕНЕДЖМЕНТ ЛИМИТЕД\"** (Venture Management Limited) - Sanctioned/linked entity\n",
      "\n",
      "These organizations form an interconnected corporate structure with control relationships between them. All of Kerimov's immediate family members (Firuza Nazimovna Kerimova, Amina Suleymanovna Kerimova, Gulnara Suleimanova KERIMOVA, and Said Kerimov) are also flagged as relatives/close associates (RCA) who are sanctioned.\n",
      "\n",
      "Additionally, entities **WANDLE HOLDINGS LIMITED** and **POLYUS FINANCE PLC** appear in the data as sanction-linked organizations, though their direct connection to Kerimov is not explicitly shown in the provided relationship data.\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  do you see any signatures of fraud in this dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: do you see any signatures of fraud in this dataset?\n",
      "======================================================================\n",
      "Found 10 relevant entities\n",
      "Expanded to 25 entities (including neighbors)\n",
      "Querying LLM...\n",
      "\n",
      "======================================================================\n",
      "ANSWER\n",
      "======================================================================\n",
      "Yes, there are several potential fraud signatures worth investigating:\n",
      "\n",
      "**Most Concerning - Potential Identity Manipulation:**\n",
      "- **Dan Symmons**, **Daniel Simons**, and **Daniel Francis Symns** appear as separate individuals but have very similar names. This could indicate:\n",
      "  - The same person using name variations to obscure beneficial ownership across multiple entities (FASTMOOR LIMITED, BLACKBROKE LIMITED, KINDLESHINE LIMITED, ZYMURGY LLP)\n",
      "  - This pattern is commonly used in fraud schemes to avoid detection and circumvent ownership disclosure requirements\n",
      "\n",
      "**Red Flags for Further Investigation:**\n",
      "\n",
      "1. **PEP Risk with Family Connection**: N. T. Wright (PEP-flagged) has a family relationship with Julian Wright (RCA-flagged). While not fraudulent per se, PEPs require enhanced due diligence, especially when family members are involved.\n",
      "\n",
      "2. **Circular Ownership Structure**: A.C Shropshire Holdings Limited and GREEN'S LODGE ESTATES LIMITED have reciprocal shareholding relationships (each holds 75-100% of the other), which is structurally suspicious and potentially used for:\n",
      "   - Asset concealment\n",
      "   - Tax manipulation\n",
      "   - Obscuring ultimate beneficial ownership\n",
      "\n",
      "3. **Threshold Structuring**: Multiple ownership stakes are maintained at 25-50% ranges, just at or below typical reporting thresholds. This could indicate intentional structuring to avoid regulatory scrutiny.\n",
      "\n",
      "4. **\"Other Influence or Control\" Relationships**: Several entities use vague \"other influence or control\" mechanisms rather than clear shareholding, which can obscure true control structures.\n",
      "\n",
      "**Recommendation**: Prioritize investigating whether Dan Symmons, Daniel Simons, and Daniel Francis Symns are the same individual, as this represents the clearest potential fraud signature in the dataset.\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your question:  do you see any signatures of fraud in this dataset?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: do you see any signatures of fraud in this dataset?\n",
      "======================================================================\n",
      "Found 10 relevant entities\n",
      "Expanded to 25 entities (including neighbors)\n",
      "Querying LLM...\n",
      "\n",
      "======================================================================\n",
      "ANSWER\n",
      "======================================================================\n",
      "Yes, there are several potential fraud signatures worth investigating:\n",
      "\n",
      "**Most Concerning - Potential Identity Manipulation:**\n",
      "- **Dan Symmons**, **Daniel Simons**, and **Daniel Francis Symns** appear as separate individuals but have very similar names. This could indicate:\n",
      "  - The same person using name variations to obscure beneficial ownership across multiple entities (FASTMOOR LIMITED, BLACKBROKE LIMITED, KINDLESHINE LIMITED, ZYMURGY LLP)\n",
      "  - This pattern is commonly used in fraud schemes to avoid detection and circumvent ownership disclosure requirements\n",
      "\n",
      "**Red Flags for Further Investigation:**\n",
      "\n",
      "1. **PEP Risk with Family Connection**: N. T. Wright (PEP-flagged) has a family relationship with Julian Wright (RCA-flagged). While not fraudulent per se, PEPs require enhanced due diligence, especially when family members are involved.\n",
      "\n",
      "2. **Circular Ownership Structure**: A.C Shropshire Holdings Limited and GREEN'S LODGE ESTATES LIMITED have reciprocal shareholding relationships (each holds 75-100% of the other), which is structurally suspicious and potentially used for:\n",
      "   - Asset concealment\n",
      "   - Tax manipulation\n",
      "   - Obscuring ultimate beneficial ownership\n",
      "\n",
      "3. **Threshold Structuring**: Multiple ownership stakes are maintained at 25-50% ranges, just at or below typical reporting thresholds. This could indicate intentional structuring to avoid regulatory scrutiny.\n",
      "\n",
      "4. **\"Other Influence or Control\" Relationships**: Several entities use vague \"other influence or control\" mechanisms rather than clear shareholding, which can obscure true control structures.\n",
      "\n",
      "**Recommendation**: Prioritize investigating whether Dan Symmons, Daniel Simons, and Daniel Francis Symns are the same individual, as this represents the clearest potential fraud signature in the dataset.\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Knowledge Graph RAG - Interactive Session\")\n",
    "print(\"=\"*70)\n",
    "print(\"Ask any question about the corporate ownership and sanctions data.\")\n",
    "print(\"The system will search LanceDB and query the knowledge graph.\")\n",
    "print(\"Type 'quit' to exit.\\n\")\n",
    "\n",
    "while True:\n",
    "    question = input(\"Your question: \").strip()\n",
    "    \n",
    "    if question.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if not question:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        ask_knowledge_graph(question)\n",
    "        print()  # Blank line for readability\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7d961-74be-40ce-bd15-06917c6a6cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
